<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.35" />


<title>Growing up - A Hugo website</title>
<meta property="og:title" content="Growing up - A Hugo website">



  







<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/logo.png"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="https://github.com/rstudio/blogdown">GitHub</a></li>
    
    <li><a href="https://twitter.com/rstudio">Twitter</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">12 min read</span>
    

    <h1 class="article-title">Growing up</h1>

    
    <span class="article-date">2015/08/16</span>
    

    <div class="article-content">
      

<p>I&rsquo;ve been playing with implementations of linear and logistic regression over the last couple of months, following the exercises from a machine learning course that I have been doing. So far I have been writing things in a very functional way, constantly defining specific functions to do what are essentially generic things.</p>

<p>I&rsquo;ve also started to write a couple of my own packages, one of which I have published on <a href="https://github.com/ivyleavedtoadflax/gapAPI/tree/v0.1.0">github</a> and <a href="https://zenodo.org/record/19743#.Vce8VPMViko">zenodo</a>. This one provides access to an API which allows users to download data collected by GPS collars on cattle. This package is entirely written as functions.</p>

<p>So, I think that it is about time that I started to mature my R programming career, and start to write in classes. I&rsquo;ve been following the excellent <a href="https://cran.r-project.org/doc/contrib/Leisch-CreatingPackages.pdf">guide</a> hosted on cran, by Friedrich Leisch, and in this post, I&rsquo;m going to re-factor some of my previously functional code for linear regression with regularisation by implementing it with classes, and the usual model related methods like <code>print()</code>, <code>summary()</code>, and <code>predict()</code>.</p>

<h2 id="before">Before</h2>

<p>So what does it look like at present? Rather than using the normal equation, this code uses the function <code>optim</code> to solve the problem:</p>

<p>$$
\min<em>{\theta}\frac{1}{2m}\Big(\sum^{m}</em>{i=1}(h<em>{\theta}(x^{(i)})-y^{(i)})^2\Big)+\frac{\lambda}{2m}\Big(\sum^{n}</em>{j=1}\theta^2_j\Big)
$$</p>

<p><code>optim</code> takes in two functions, the cost function $J_\theta$ (<code>J</code>):</p>

<p>{% highlight r %}
J &lt;- function(X, y, theta, lambda) {</p>

<p>m &lt;- length(y)</p>

<p>theta1 &lt;- theta</p>

<p># Ensure that regularisation is not operating on \theta_0</p>

<p>theta1[1] &lt;- 0</p>

<p>error &lt;- tcrossprod(theta,X)
  error &lt;- as.vector(error) - y
  error1 &lt;- crossprod(error,error)</p>

<p>reg &lt;- (lambda/(2*m)) * crossprod(theta1, theta1)</p>

<p>cost &lt;- (1/(2 * m)) * error1 + reg</p>

<p>return(cost)</p>

<p>}
{% endhighlight %}</p>

<p>and a gradient function (<code>gR</code>):</p>

<p>{% highlight r %}
gR &lt;- function(X, y, theta, lambda) {</p>

<p>theta1 &lt;- theta
  theta1[1] &lt;- 0</p>

<p>m &lt;- length(y)</p>

<p>error &lt;- tcrossprod(theta,X)
  error &lt;- as.vector(error) - y
  error &lt;- (1/m) * crossprod(error,X)</p>

<p>reg &lt;- (lambda/(m)) * theta1</p>

<p>delta &lt;- error + reg</p>

<p>return(delta)</p>

<p>}
{% endhighlight %}</p>

<p>These are taken as inputs in to the <code>optim</code> function:</p>

<p>{% highlight r %}
theta &lt;- rep(1,2)
lambda &lt;- 0
x &lt;- mpg$displ
y &lt;- mpg$hwy</p>

<p>optim_out &lt;- optim(
  par = theta,
  fn = function(t) J(cbind(1, x), y, t, lambda),
  gr = function(t) gR(cbind(1, x), y, t, lambda),
  method = &ldquo;BFGS&rdquo;
)
{% endhighlight %}</p>

<p>And calling this, we get:</p>

<p>{% highlight r %}
optim_out
{% endhighlight %}</p>

<p>{% highlight text %}</p>

<h2 id="par">$par</h2>

<h2 id="1-35-697650-3-530589">[1] 35.697650 -3.530589</h2>

<h2 id="value">$value</h2>

<h2 id="1-7-294506">[1] 7.294506</h2>

<h2 id="counts">$counts</h2>

<h2 id="function-gradient">function gradient</h2>

<h2 id="21-13">21       13</h2>

<h2 id="convergence">$convergence</h2>

<h2 id="1-0">[1] 0</h2>

<h2 id="message">$message</h2>

<h2 id="null">NULL</h2>

<p>{% endhighlight %}</p>

<p>Just to check, I compare this with a simple linear regression with <code>lm()</code>.</p>

<p>{% highlight r %}
lm_model &lt;- lm(hwy ~ displ, data = mpg)
coef(lm_model)
{% endhighlight %}</p>

<p>{% highlight text %}</p>

<h2 id="intercept-displ">(Intercept)       displ</h2>

<h2 id="35-697651-3-530589">35.697651   -3.530589</h2>

<p>{% endhighlight %}</p>

<p>So the coefficients are not the same, but are pretty close nonetheless.</p>

<p>{% highlight r %}
all.equal(
  as.numeric(optim_out$par),
  as.numeric(coef(lm_model))
)
{% endhighlight %}</p>

<p>{% highlight text %}</p>

<h2 id="1-mean-relative-difference-3-402685e-08">[1] &ldquo;Mean relative difference: 3.402685e-08&rdquo;</h2>

<p>{% endhighlight %}</p>

<h2 id="converting-to-s3-classes-and-methods">Converting to S3 classes and methods</h2>

<h3 id="model-function">Model function</h3>

<p>As mentioned, I&rsquo;m following this <a href="[guide](https://cran.r-project.org/doc/contrib/Leisch-CreatingPackages.pdf)">guide</a> pretty closely, as it does exactly what I want to do. So I will start by producing a function to wrap up the <code>optim</code> call. <code>optim</code> must take inputs of functions for the cost and gradient, and so there is not too much that can be done to these functions as far as I can see, so for the moment I will leave them be.</p>

<p>{% highlight r %}
vlrr_est &lt;- function(x, y, lambda)</p>

<p>{</p>

<p>theta &lt;- rep(1,ncol(x))</p>

<p>optim_out &lt;- optim(
    par = theta,
    fn = function(t) J(x, y, t, lambda),
    gr = function(t) gR(x, y, t, lambda),
    method = &ldquo;BFGS&rdquo;
  )</p>

<p>df = nrow(x) - ncol(x)</p>

<p># Calculate the variance</p>

<p>sigma2 &lt;- sum((y - x %*% optim_out$par)^2) / df</p>

<p># Compute covariance with sigma^2 * (X^{T}X)^-1. Note that Leisch counsels
  # against using this method of calculating the covariance matrix. Instead he
  # recommends using QR decomposition. As my present implementation does not
  # solve the normal equation (X^{T}X)^{âˆ’1}X^{T}y but instead relies on optim I
  # do not have the products of the QR decomposition to use in the matrix
  # inverse in the standard lm implementation: vcov &lt;- sigma2 * chol2inv(qx$qr).
  # This implementation will do for now&hellip; Note that this requires MASS::ginv().
  # Mildly faster to use crossprod than %*%</p>

<p>vcov &lt;- sigma2 * ginv(crossprod(x,x))</p>

<p># Create a standardised output similar to that of lm()</p>

<p>list(
    coefficients = optim_out$par,
    error = optim_out$value,
    convergence = optim_out$convergence,
    message = optim_out$message,
    vcov = vcov,
    sigma = sqrt(sigma2),
    df = df
    )
}
{% endhighlight %}</p>

<p>For now, <code>x</code> must be specified as the usual $\mathbb{R}^{m \times n+1}$ matrix consisting of a column of 1s which correspond to the intercept.</p>

<p>{% highlight r %}
vlrr_est(x = cbind(1,mpg$displ), y = mpg$hwy, lambda = 0)
{% endhighlight %}</p>

<p>{% highlight text %}</p>

<h2 id="coefficients">$coefficients</h2>

<h2 id="1-35-697650-3-530589-1">[1] 35.697650 -3.530589</h2>

<h2 id="error">$error</h2>

<h2 id="1-7-294506-1">[1] 7.294506</h2>

<h2 id="convergence-1">$convergence</h2>

<h2 id="1-0-1">[1] 0</h2>

<h2 id="message-1">$message</h2>

<h2 id="null-1">NULL</h2>

<h2 id="vcov">$vcov</h2>

<h2 id="1-2">[,1]        [,2]</h2>

<h2 id="1-0-5189295-0-13135737">[1,]  0.5189295 -0.13135737</h2>

<h2 id="2-0-1313574-0-03783558">[2,] -0.1313574  0.03783558</h2>

<h2 id="sigma">$sigma</h2>

<h2 id="1-3-835985">[1] 3.835985</h2>

<h2 id="df">$df</h2>

<h2 id="1-232">[1] 232</h2>

<p>{% endhighlight %}</p>

<p>So far so good. Now define the function <code>vlrr()</code> and the default method for it:</p>

<h3 id="vlrr-class-and-default-method">vlrr class and default method</h3>

<p>{% highlight r %}</p>

<h1 id="this-is-almost-entirely-lifted-from-leisch-2009">This is almost entirely lifted from Leisch (2009)</h1>

<p>vlrr &lt;- function(x, y, lambda, &hellip;) UseMethod(&ldquo;vlrr&rdquo;)</p>

<p>vlrr.default &lt;- function(x, y, lambda = 0, &hellip;) {</p>

<p># Could put in some more verbose checks of the input here.</p>

<p>x &lt;- as.matrix(x)
  y &lt;- as.numeric(y)
  lambda &lt;- as.numeric(lambda)</p>

<p>est &lt;- vlrr_est(x, y, lambda)</p>

<p>est$lambda = lambda
  est$fitted.values &lt;- as.vector(x %*% est$coefficients)
  est$residuals &lt;- y - est$fitted.values
  est$call &lt;- match.call()</p>

<p>class(est) &lt;- &ldquo;vlrr&rdquo;
  est
}
{% endhighlight %}</p>

<p>So now if I call call <code>vlrr</code> or the <code>vlrr.default</code> function, I should get the same right?</p>

<p>{% highlight r %}
identical(
  vlrr.default(cbind(1, mpg$disp), mpg$hwy, 0),
  vlrr(cbind(1, mpg$disp), mpg$hwy, 0)
)
{% endhighlight %}</p>

<p>{% highlight text %}</p>

<h2 id="1-true">[1] TRUE</h2>

<p>{% endhighlight %}</p>

<p>And because I defined the output in a standard way, I can use the standard methods to interrogate it:</p>

<p>{% highlight r %}
model &lt;- vlrr(cbind(1, mpg$disp), mpg$hwy, 0)</p>

<p>coef(model)
{% endhighlight %}</p>

<p>{% highlight text %}</p>

<h2 id="1-35-697650-3-530589-2">[1] 35.697650 -3.530589</h2>

<p>{% endhighlight %}</p>

<p>{% highlight r %}
fitted.values(model) %&gt;% head
{% endhighlight %}</p>

<p>{% highlight text %}</p>

<h2 id="1-29-34259-29-34259-28-63647-28-63647-25-81200-25-81200">[1] 29.34259 29.34259 28.63647 28.63647 25.81200 25.81200</h2>

<p>{% endhighlight %}</p>

<p>{% highlight r %}
resid(model) %&gt;% head
{% endhighlight %}</p>

<p>{% highlight text %}</p>

<h2 id="1-0-3425906-0-3425906-2-3635271-1-3635271-0-1879979-0-1879979">[1] -0.3425906 -0.3425906  2.3635271  1.3635271  0.1879979  0.1879979</h2>

<p>{% endhighlight %}</p>

<h3 id="print-method">Print method</h3>

<p>I won&rsquo;t <code>print(model)</code> as at present is will print all the slots in turn:</p>

<p>{% highlight r %}
attributes(model)
{% endhighlight %}</p>

<p>{% highlight text %}</p>

<h2 id="names">$names</h2>

<h2 id="1-coefficients-error-convergence-message">[1] &ldquo;coefficients&rdquo;  &ldquo;error&rdquo;         &ldquo;convergence&rdquo;   &ldquo;message&rdquo;</h2>

<h2 id="5-vcov-sigma-df-lambda">[5] &ldquo;vcov&rdquo;          &ldquo;sigma&rdquo;         &ldquo;df&rdquo;            &ldquo;lambda&rdquo;</h2>

<h2 id="9-fitted-values-residuals-call">[9] &ldquo;fitted.values&rdquo; &ldquo;residuals&rdquo;     &ldquo;call&rdquo;</h2>

<h2 id="class">$class</h2>

<h2 id="1-vlrr">[1] &ldquo;vlrr&rdquo;</h2>

<p>{% endhighlight %}</p>

<p>This ends up being very long, so it would be good to write a print method that returns something a bit shorter.</p>

<p>{% highlight r %}
print.vlrr &lt;- function(x, &hellip;) {
  cat(&ldquo;Call:\n&rdquo;)
  print(x$call)
  cat(&rdquo;\nError:\n&rdquo;)
  print(x$error)
  cat(&rdquo;\nCoefficients:\n&rdquo;)
  print(x$coefficients)
}</p>

<p>print(model)
{% endhighlight %}</p>

<p>{% highlight text %}</p>

<h2 id="call">Call:</h2>

<h2 id="vlrr-default-x-cbind-1-mpg-disp-y-mpg-hwy-lambda-0">vlrr.default(x = cbind(1, mpg$disp), y = mpg$hwy, lambda = 0)</h2>

<h2 id="error-1">Error:</h2>

<h2 id="1-7-294506-2">[1] 7.294506</h2>

<h2 id="coefficients-1">Coefficients:</h2>

<h2 id="1-35-697650-3-530589-3">[1] 35.697650 -3.530589</h2>

<p>{% endhighlight %}</p>

<p>Better.</p>

<h3 id="summary-method">Summary method</h3>

<p>Model functions also usually have a <code>summary</code> method which prints out a nice summary of the model (e.g. <code>summary.lm</code>). For now I&rsquo;ll just copy the default method given by Leisch, plus additional information about <code>optim</code>&rsquo;s convergence success.</p>

<p>{% highlight r %}
summary.vlrr &lt;- function(object, &hellip;) {</p>

<p># It would be nice to be able to compare the success of models from the
  # summary output. Here I include a simple mean squared error.</p>

<p>m &lt;- length(object$fitted.values)
  error &lt;- object$residuals
  MSE &lt;- as.numeric(1/m * crossprod(error, error))</p>

<p>se &lt;- sqrt(diag(object$vcov))
  tval &lt;- coef(object) / se</p>

<p># Note that here the p value is for testing the null hypothesis that the
  # coefficients are different from zero</p>

<p>TAB &lt;- cbind(
    Estimate = coef(object),
    StdErr = se,
    t.value = tval,
    p.value = 2*pt(-abs(tval), df=object$df)
  )
  res &lt;- list(
    convergence = object$convergence,
    message = object$message,
    call = object$call,
    coefficients = TAB,
    MSE = MSE
  )</p>

<p>class(res) &lt;-&ldquo;summary.vlrr&rdquo;
  res
}</p>

<p>summary(model)
{% endhighlight %}</p>

<p>{% highlight text %}</p>

<h2 id="convergence-2">$convergence</h2>

<h2 id="1-0-2">[1] 0</h2>

<h2 id="message-2">$message</h2>

<h2 id="null-2">NULL</h2>

<h2 id="call-1">$call</h2>

<h2 id="vlrr-default-x-cbind-1-mpg-disp-y-mpg-hwy-lambda-0-1">vlrr.default(x = cbind(1, mpg$disp), y = mpg$hwy, lambda = 0)</h2>

<h2 id="coefficients-2">$coefficients</h2>

<h2 id="estimate-stderr-t-value-p-value">Estimate    StdErr   t.value       p.value</h2>

<h2 id="1-35-697650-0-7203676-49-55477-2-123533e-125">[1,] 35.697650 0.7203676  49.55477 2.123533e-125</h2>

<h2 id="2-3-530589-0-1945137-18-15085-2-038996e-46">[2,] -3.530589 0.1945137 -18.15085  2.038996e-46</h2>

<h2 id="mse">$MSE</h2>

<h2 id="1-14-58901">[1] 14.58901</h2>

<h2 id="attr-class">attr(,&ldquo;class&rdquo;)</h2>

<h2 id="1-summary-vlrr">[1] &ldquo;summary.vlrr&rdquo;</h2>

<p>{% endhighlight %}</p>

<p>This is a bit messy, but we can define a <code>print</code> method for <code>summary</code> using the <code>Coefmat</code> function to order things nicely in the coefficients table.</p>

<p>{% highlight r %}
print.summary.vlrr &lt;- function(x, &hellip;) {</p>

<p>cat(&ldquo;Vectorised linear regression by optim:\n&rdquo;)
  cat(&rdquo;\n&rdquo;)
  cat(&ldquo;Convergence (see ?optim):\n&rdquo;)
  print(x$convergence)
  print(x$message)</p>

<p>cat(&rdquo;\n&rdquo;)
  cat(&ldquo;Call:\n&rdquo;)</p>

<p>print(x$call)
  cat(&rdquo;\n&rdquo;)</p>

<p>cat(&ldquo;Lambda:\n&rdquo;)</p>

<p>print(x$lambda)
  cat(&rdquo;\n&rdquo;)</p>

<p>printCoefmat(
    x$coefficients,
    P.value = TRUE,
    has.Pvalue = TRUE
  )</p>

<p>cat(&rdquo;\n&rdquo;)
  cat(&ldquo;MSE:\n&rdquo;)
  print(x$MSE)
}</p>

<p>print(summary(model))
{% endhighlight %}</p>

<p>{% highlight text %}</p>

<h2 id="vectorised-linear-regression-by-optim">Vectorised linear regression by optim:</h2>

<h2 id="convergence-see-optim">Convergence (see ?optim):</h2>

<h2 id="1-0-3">[1] 0</h2>

<h2 id="null-3">NULL</h2>

<h2 id="call-2">Call:</h2>

<h2 id="vlrr-default-x-cbind-1-mpg-disp-y-mpg-hwy-lambda-0-2">vlrr.default(x = cbind(1, mpg$disp), y = mpg$hwy, lambda = 0)</h2>

<h2 id="lambda">Lambda:</h2>

<h2 id="null-4">NULL</h2>

<h2 id="estimate-stderr-t-value-p-value-1">Estimate   StdErr t.value   p.value</h2>

<h2 id="1-35-69765-0-72037-49-555-2-2e-16">[1,] 35.69765  0.72037  49.555 &lt; 2.2e-16 ***</h2>

<h2 id="2-3-53059-0-19451-18-151-2-2e-16">[2,] -3.53059  0.19451 -18.151 &lt; 2.2e-16 ***</h2>

<h2 id="toc_78">&mdash;</h2>

<h2 id="signif-codes-0-0-001-0-01-0-05-0-1-1">Signif. codes:  0 &lsquo;*<strong>&rsquo; 0.001 &lsquo;</strong>&rsquo; 0.01 &lsquo;*&rsquo; 0.05 &lsquo;.&rsquo; 0.1 &lsquo; &rsquo; 1</h2>

<h2 id="mse-1">MSE:</h2>

<h2 id="1-14-58901-1">[1] 14.58901</h2>

<p>{% endhighlight %}</p>

<p>Great, so this looks a lot more like the output we would expect from <code>lm()</code>, plus we have some statistics on the likelihood that our coefficients are different from zero.</p>

<h3 id="formula-method">Formula method</h3>

<p>It&rsquo;s a bit tiresome having to specify <code>x=</code> and <code>y=</code> when in <code>lm()</code> and other models, we are able to specify a formula. In addition, if we want to include interaction terms $x_1 \times x_2$ for instance, this would need to be done in the input matrix x. By implementing a <code>formula</code> method, this can all be automated. This also gets us off the hook with having to <code>cbind(1,x)</code>.</p>

<p>At present I must do:</p>

<p>{% highlight r %}
vlrr(x=cbind(1,x),y=y)
{% endhighlight %}</p>

<p>But after implementing the <code>formula</code> method&hellip;</p>

<p>{% highlight r %}
vlrr.formula &lt;- function(formula, data = list(), &hellip;) {</p>

<p>mf &lt;- model.frame(formula = formula, data = data)
  x &lt;- model.matrix(attr(mf, &ldquo;terms&rdquo;), data = mf)
  y &lt;- model.response(mf)</p>

<p>est &lt;- vlrr.default(x, y, &hellip;)
  est$call &lt;- match.call()
  est$formula &lt;- formula
  est</p>

<p>}
{% endhighlight %}</p>

<p>&hellip;things get much  much simpler!</p>

<p>{% highlight r %}
model &lt;- vlrr(hwy ~ displ,lambda = 0, data = mpg)
print(model)
{% endhighlight %}</p>

<p>{% highlight text %}</p>

<h2 id="call-3">Call:</h2>

<h2 id="vlrr-formula-formula-hwy-displ-data-mpg-lambda-0">vlrr.formula(formula = hwy ~ displ, data = mpg, lambda = 0)</h2>

<h2 id="error-2">Error:</h2>

<h2 id="1-7-294506-3">[1] 7.294506</h2>

<h2 id="coefficients-3">Coefficients:</h2>

<h2 id="1-35-697650-3-530589-4">[1] 35.697650 -3.530589</h2>

<p>{% endhighlight %}</p>

<p>and how about:</p>

<p>{% highlight r %}
summary(model)
{% endhighlight %}</p>

<p>{% highlight text %}</p>

<h2 id="convergence-3">$convergence</h2>

<h2 id="1-0-4">[1] 0</h2>

<h2 id="message-3">$message</h2>

<h2 id="null-5">NULL</h2>

<h2 id="call-4">$call</h2>

<h2 id="vlrr-formula-formula-hwy-displ-data-mpg-lambda-0-1">vlrr.formula(formula = hwy ~ displ, data = mpg, lambda = 0)</h2>

<h2 id="coefficients-4">$coefficients</h2>

<h2 id="estimate-stderr-t-value-p-value-2">Estimate    StdErr   t.value       p.value</h2>

<h2 id="1-35-697650-0-7203676-49-55477-2-123533e-125-1">[1,] 35.697650 0.7203676  49.55477 2.123533e-125</h2>

<h2 id="2-3-530589-0-1945137-18-15085-2-038996e-46-1">[2,] -3.530589 0.1945137 -18.15085  2.038996e-46</h2>

<h2 id="mse-2">$MSE</h2>

<h2 id="1-14-58901-2">[1] 14.58901</h2>

<h2 id="attr-class-1">attr(,&ldquo;class&rdquo;)</h2>

<h2 id="1-summary-vlrr-1">[1] &ldquo;summary.vlrr&rdquo;</h2>

<p>{% endhighlight %}</p>

<h3 id="predict-method">Predict method</h3>

<p>The last method I want to implement is <code>predict</code> as this makes it much easier to use the model once fit. Again I&rsquo;m relying on Leisch here.</p>

<p>{% highlight r %}
predict.vlrr &lt;- function(object, newdata = NULL, &hellip;) {</p>

<p># If no new data, the just present the fitted values from the model</p>

<p>if(is.null(newdata)) {
    y &lt;- fitted(object)
  }
  else{
    if(!is.null(object$formula)){
      ## model has been fitted using formula interface
      x &lt;- model.matrix(object$formula, newdata)
    }
    else{
      # newdata is just a matrix
      x &lt;- newdata
    }<br />
    y &lt;- as.vector(x %*% coef(object))
  }
  y
}
{% endhighlight %}</p>

<h2 id="testing-it-out">Testing it out</h2>

<p>So finally we can take this model and apply it to some other data. Here I take the model I built on fuel consumption from the <code>mpg</code> dataset, and use it to predict displacement values (<code>disp</code>) from the <code>mtcars</code> dataset. Note that displacement is given in cubic inches in <code>mtcars</code> but litres in <code>mpg</code> so needs to be multiplied by 0.0163 to put it on the same scale.</p>

<p>{% highlight r %}</p>

<h1 id="create-base-plot-and-fit-using-lm">Create base plot and fit using lm</h1>

<p>plot(
  mpg ~ I(disp * 0.0163),
  data = mtcars,
  title = &ldquo;mtcars&rdquo;
)</p>

<p>abline(
  lm(mpg~I(disp * 0.0163), data = mtcars),
  col = &ldquo;blue&rdquo;,
  type = &ldquo;o&rdquo;
  )</p>

<h1 id="use-predict-method-on-mpg-model-and-predict-over-new-data">Use predict method on mpg model and predict over new data</h1>

<p>new_y &lt;- predict(
  model,
  newdata = list(hwy = mtcars$disp, displ = mtcars$disp * 0.0163)
)</p>

<p>points(
  mtcars$disp * 0.0163,
  new_y,
  col = &ldquo;red&rdquo;,
  type = &ldquo;o&rdquo;
)
{% endhighlight %}</p>

<p><a href="/figures/2015-08-16-testing-it-out-1.png"><img src="/figures/2015-08-16-testing-it-out-1.png" alt="plot of chunk 2015-08-16-testing-it-out" /></a></p>

<h2 id="writing-a-package">Writing a package</h2>

<p>So the obvious thing to do now that this has all been done, is to wrap everything up into a package. I&rsquo;m not going to go through the steps to do that here because it is a little bit long winded, and much better covered in the <a href="https://cran.r-project.org/doc/contrib/Leisch-CreatingPackages.pdf">Leisch</a> guide, and <a href="http://r-pkgs.had.co.nz/">here</a> by Hadley Wickham.</p>

<p>It&rsquo;s a pretty simple process, and actually the most onerous (and arguably the most important) thing is to properly document all the functions. So I have put in a little bit of time, and produced the package <code>vlrr</code>, which is now available from a github <a href="https://github.com/ivyleavedtoadflax/vlrr">repo</a>.</p>

<p>This can be installed direct from within R using <code>devtools::install_github(&quot;ivyleavedtoadflax/vlrr&quot;)</code>. The library can then be called and run like any other.</p>

<p>{% highlight r %}
library(vlrr)</p>

<p>model &lt;- vlrr(Volume ~ Girth, data = trees)</p>

<p>summary(model)
{% endhighlight %}</p>

<p>{% highlight text %}</p>

<h2 id="vectorised-linear-regression-by-optim-1">Vectorised linear regression by optim:</h2>

<h2 id="convergence-see-optim-1">Convergence (see ?optim):</h2>

<h2 id="1-0-5">[1] 0</h2>

<h2 id="null-6">NULL</h2>

<h2 id="call-5">Call:</h2>

<h2 id="vlrr-formula-formula-volume-girth-data-trees">vlrr.formula(formula = Volume ~ Girth, data = trees)</h2>

<h2 id="lambda-1">Lambda:</h2>

<h2 id="null-7">NULL</h2>

<h2 id="estimate-stderr-t-value-p-value-3">Estimate    StdErr t.value   p.value</h2>

<h2 id="1-36-94331-3-36514-10-978-7-622e-12">[1,] -36.94331   3.36514 -10.978 7.622e-12 ***</h2>

<h2 id="2-5-06585-0-24738-20-478-2-2e-16">[2,]   5.06585   0.24738  20.478 &lt; 2.2e-16 ***</h2>

<h2 id="toc_119">&mdash;</h2>

<h2 id="signif-codes-0-0-001-0-01-0-05-0-1-1-1">Signif. codes:  0 &lsquo;*<strong>&rsquo; 0.001 &lsquo;</strong>&rsquo; 0.01 &lsquo;*&rsquo; 0.05 &lsquo;.&rsquo; 0.1 &lsquo; &rsquo; 1</h2>

<h2 id="mse-3">MSE:</h2>

<h2 id="1-16-91299">[1] 16.91299</h2>

<p>{% endhighlight %}</p>

<p>{% highlight r %}
plot(Volume ~ Girth,data = trees)
abline(
  model,
  col = &ldquo;red&rdquo;,
  lwd = 2
  )</p>

<h1 id="something-more-complicated">Something more complicated</h1>

<p>model1 &lt;- vlrr(Volume~poly(Girth,degree = 3), lambda = 0.1,data = trees)
summary(model1)
{% endhighlight %}</p>

<p>{% highlight text %}</p>

<h2 id="vectorised-linear-regression-by-optim-2">Vectorised linear regression by optim:</h2>

<h2 id="convergence-see-optim-2">Convergence (see ?optim):</h2>

<h2 id="1-0-6">[1] 0</h2>

<h2 id="null-8">NULL</h2>

<h2 id="call-6">Call:</h2>

<h2 id="vlrr-formula-formula-volume-poly-girth-degree-3-data-trees">vlrr.formula(formula = Volume ~ poly(Girth, degree = 3), data = trees,</h2>

<h2 id="lambda-0-1">lambda = 0.1)</h2>

<h2 id="lambda-2">Lambda:</h2>

<h2 id="null-9">NULL</h2>

<h2 id="estimate-stderr-t-value-p-value-4">Estimate   StdErr t.value   p.value</h2>

<h2 id="1-30-17097-0-66188-45-5839-2-2e-16">[1,] 30.17097  0.66188 45.5839 &lt; 2.2e-16 ***</h2>

<h2 id="2-79-15766-3-68518-21-4800-2-2e-16">[2,] 79.15766  3.68518 21.4800 &lt; 2.2e-16 ***</h2>

<h2 id="3-13-26527-3-68518-3-5996-0-001263">[3,] 13.26527  3.68518  3.5996  0.001263 **</h2>

<h2 id="4-2-75774-3-68518-0-7483-0-460729">[4,]  2.75774  3.68518  0.7483  0.460729</h2>

<h2 id="toc_138">&mdash;</h2>

<h2 id="signif-codes-0-0-001-0-01-0-05-0-1-1-2">Signif. codes:  0 &lsquo;*<strong>&rsquo; 0.001 &lsquo;</strong>&rsquo; 0.01 &lsquo;*&rsquo; 0.05 &lsquo;.&rsquo; 0.1 &lsquo; &rsquo; 1</h2>

<h2 id="mse-4">MSE:</h2>

<h2 id="1-11-82823">[1] 11.82823</h2>

<p>{% endhighlight %}</p>

<p>{% highlight r %}
lines(
  trees$Girth,
  model1$fitted.values,
  col = &ldquo;blue&rdquo;,
  lwd = 2,
  lty = 2
  )
{% endhighlight %}</p>

<p><a href="/figures/2015-08-16-trees-dataset-1.png"><img src="/figures/2015-08-16-trees-dataset-1.png" alt="plot of chunk 2015-08-16-trees-dataset" /></a></p>

<p>{% highlight r %}
sessionInfo()<br />
{% endhighlight %}</p>

<p>{% highlight text %}</p>

<h2 id="r-version-3-2-0-2015-04-16">R version 3.2.0 (2015-04-16)</h2>

<h2 id="platform-x86-64-unknown-linux-gnu-64-bit">Platform: x86_64-unknown-linux-gnu (64-bit)</h2>

<h2 id="running-under-ubuntu-14-04-2-lts">Running under: Ubuntu 14.04.2 LTS</h2>

<h2 id="locale">locale:</h2>

<h2 id="1-lc-ctype-en-gb-utf-8-lc-numeric-c">[1] LC_CTYPE=en_GB.UTF-8       LC_NUMERIC=C</h2>

<h2 id="3-lc-time-en-gb-utf-8-lc-collate-en-gb-utf-8">[3] LC_TIME=en_GB.UTF-8        LC_COLLATE=en_GB.UTF-8</h2>

<h2 id="5-lc-monetary-en-gb-utf-8-lc-messages-en-gb-utf-8">[5] LC_MONETARY=en_GB.UTF-8    LC_MESSAGES=en_GB.UTF-8</h2>

<h2 id="7-lc-paper-en-gb-utf-8-lc-name-c">[7] LC_PAPER=en_GB.UTF-8       LC_NAME=C</h2>

<h2 id="9-lc-address-c-lc-telephone-c">[9] LC_ADDRESS=C               LC_TELEPHONE=C</h2>

<h2 id="11-lc-measurement-en-gb-utf-8-lc-identification-c">[11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C</h2>

<h2 id="attached-base-packages">attached base packages:</h2>

<h2 id="1-methods-stats-graphics-grdevices-utils-datasets-base">[1] methods   stats     graphics  grDevices utils     datasets  base</h2>

<h2 id="other-attached-packages">other attached packages:</h2>

<h2 id="1-vlrr-0-1-mass-7-3-40-tidyr-0-2-0-ggplot2-1-0-1">[1] vlrr_0.1       MASS_7.3-40    tidyr_0.2.0    ggplot2_1.0.1</h2>

<h2 id="5-ucminf-1-1-3-boot-1-3-16-magrittr-1-5-dplyr-0-4-1">[5] ucminf_1.1-3   boot_1.3-16    magrittr_1.5   dplyr_0.4.1</h2>

<h2 id="9-testthat-0-9-1-knitr-1-10">[9] testthat_0.9.1 knitr_1.10</h2>

<h2 id="loaded-via-a-namespace-and-not-attached">loaded via a namespace (and not attached):</h2>

<h2 id="1-rcpp-0-11-5-munsell-0-4-2-colorspace-1-2-6">[1] Rcpp_0.11.5       munsell_0.4.2     colorspace_1.2-6</h2>

<h2 id="4-stringr-1-0-0-plyr-1-8-2-tools-3-2-0">[4] stringr_1.0.0     plyr_1.8.2        tools_3.2.0</h2>

<h2 id="7-parallel-3-2-0-grid-3-2-0-gtable-0-1-2">[7] parallel_3.2.0    grid_3.2.0        gtable_0.1.2</h2>

<h2 id="10-dbi-0-3-1-checkpoint-0-3-10-assertthat-0-1">[10] DBI_0.3.1         checkpoint_0.3.10 assertthat_0.1</h2>

<h2 id="13-digest-0-6-8-reshape2-1-4-1-formatr-1-2">[13] digest_0.6.8      reshape2_1.4.1    formatR_1.2</h2>

<h2 id="16-evaluate-0-7-stringi-0-4-1-scales-0-2-4">[16] evaluate_0.7      stringi_0.4-1     scales_0.2.4</h2>

<h2 id="19-proto-0-3-10">[19] proto_0.3-10</h2>

<p>{% endhighlight %}</p>

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    

    
<script src="/js/math-code.js"></script>
<script async src="//cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
  </body>
</html>

